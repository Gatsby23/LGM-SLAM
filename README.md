# LGM-SLAM
An official implmentation of Visual Localization and Mapping Leveraging the Constraints of Local Ground Manifolds

## Install
This project is implmented based on ORB_SLAM2. All the DEPENDENCIES are the same as ORB_SLAM2's.

## Datasets management
This project uses kitti odometery datasets. The structure is, for example, in kitti/00:

![image](https://user-images.githubusercontent.com/73513416/172988794-a4ca0456-68f2-4667-8664-ef46a976bfd9.png)

You can use gray or color images to test the algorithm. The segmentation of the images is generated by a semantic segmentation algorithm [Kittiseg](https://github.com/MarvinTeichmann/KittiSeg).

## Running
```
./Examples/Stereo/stereo_kitti_seg Vocabulary/ORBvoc.txt Examples/Stereo/KITTI04-12.yaml KITTI/sequence/folder
```

## Cite
If you refer to this code in an academic work, please cite:

@article{zhou2022visual,
  title={Visual Localization and Mapping Leveraging the Constraints of Local Ground Manifolds},
  author={Zhou, Pengkun and Liu, Yuzhen and Gu, Pengfei and Liu, Jiacheng and Meng, Ziyang},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={4196--4203},
  year={2022},
  publisher={IEEE}
}

